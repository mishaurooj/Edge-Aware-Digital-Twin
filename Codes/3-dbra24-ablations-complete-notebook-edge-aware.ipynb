{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#6C5CE7\">DBRA24 Digital Twin Anomaly ‚Äî End-to-End Pipeline with A1‚ÄìA10 Ablations</span>\n",
    "\n",
    "<span style=\"background:#E3F2FD;color:#0D47A1;padding:6px 10px;border-radius:6px;display:inline-block;\">\n",
    "<strong>Dataset</strong>: <code>/kaggle/input/driver-behavior-and-route-anomaly-dataset-dbra24/driver_behavior_route_anomaly_dataset_with_derived_features.csv</code>\n",
    "</span>\n",
    "\n",
    "This notebook is **ready to run on Kaggle**. It:\n",
    "- trains **A1‚ÄìA10 ablations** (GBM baseline, Bi-LSTM variants, TCN-Small)\n",
    "- saves models to <code>/kaggle/working/models/</code>\n",
    "- exports a single **Excel** report to <code>/kaggle/working/DBRA24_results.xlsx</code>\n",
    "- writes **plots** (PR curves, reliability, confusion matrices, ROC) to <code>/kaggle/working/plots/</code>\n",
    "- prints a **final comparison table** (easy to paste in your paper/report)\n",
    "\n",
    "> Tip: Turn on GPU in the Kaggle Notebook settings for faster training (optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#00B894\">Table of Contents</span>\n",
    "1. üîß Setup (Installs & Imports)  \n",
    "2. ‚öôÔ∏è Config (paths, seeds, hyperparameters)  \n",
    "3. üì• Load & Inspect Data  \n",
    "4. üß≠ Feature Groups & Light Engineering  \n",
    "5. üß± Windowing into Sequences (T=60s, stride=5s)  \n",
    "6. ‚úÇÔ∏è Split by Driver (train/val/test)  \n",
    "7. üìè Scaling & PyTorch Datasets  \n",
    "8. üß† Models (Bi-LSTM, TCN-Small, Gating)  \n",
    "9. üìê Losses & Metrics (PR-AUC, F1, RMSE, ECE, TTD, FP/h, Latency, FLOPs)  \n",
    "10. üèÉ Training/Evaluation Utilities  \n",
    "11. üå≥ A1 ‚Äî GBM (No Mobility, Temporal-Agnostic)  \n",
    "12. üß™ A2‚ÄìA10 ‚Äî Ablations (one-by-one)  \n",
    "13. üìä Results Export (Excel, CSV, Plots) + Final Comparison Table  \n",
    "14. üìù Notes & Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) üîß Setup ‚Äî Installs\n",
    "Safe to re-run. Kaggle usually has most deps. We install a few extras (quietly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:32:56.640006Z",
     "iopub.status.busy": "2025-10-11T15:32:56.639722Z",
     "iopub.status.idle": "2025-10-11T15:34:20.419067Z",
     "shell.execute_reply": "2025-10-11T15:34:20.418290Z",
     "shell.execute_reply.started": "2025-10-11T15:32:56.639984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm ‚úì\n",
      "xgboost ‚úì\n",
      "Installing thop ‚Ä¶\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 363.4/363.4 MB 4.5 MB/s eta 0:00:00\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13.8/13.8 MB 97.0 MB/s eta 0:00:00\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 24.6/24.6 MB 76.7 MB/s eta 0:00:00\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 883.7/883.7 kB 40.5 MB/s eta 0:00:00\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 664.8/664.8 MB 1.9 MB/s eta 0:00:00\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 211.5/211.5 MB 9.1 MB/s eta 0:00:00\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 56.3/56.3 MB 31.8 MB/s eta 0:00:00\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127.9/127.9 MB 13.5 MB/s eta 0:00:00\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 207.5/207.5 MB 8.2 MB/s eta 0:00:00\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21.1/21.1 MB 85.6 MB/s eta 0:00:00\n",
      "openpyxl ‚úì\n",
      "torchmetrics ‚úì\n"
     ]
    }
   ],
   "source": [
    "# If internet is restricted, you can comment these lines. On Kaggle, this is OK to run.\n",
    "import sys, subprocess, importlib\n",
    "\n",
    "def ensure(pkg, pip_name=None):\n",
    "    pip_name = pip_name or pkg\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "        print(f\"{pkg} ‚úì\")\n",
    "    except Exception:\n",
    "        print(f\"Installing {pip_name} ‚Ä¶\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pip_name])\n",
    "\n",
    "for p in [\n",
    "    (\"lightgbm\",\"lightgbm\"),\n",
    "    (\"xgboost\",\"xgboost\"),\n",
    "    (\"thop\",\"thop\"),\n",
    "    (\"openpyxl\",\"openpyxl\"),\n",
    "    (\"torchmetrics\",\"torchmetrics==1.4.0\"),\n",
    "]:\n",
    "    ensure(*p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) ‚öôÔ∏è Imports & Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:34:20.421040Z",
     "iopub.status.busy": "2025-10-11T15:34:20.420249Z",
     "iopub.status.idle": "2025-10-11T15:34:20.431253Z",
     "shell.execute_reply": "2025-10-11T15:34:20.430610Z",
     "shell.execute_reply.started": "2025-10-11T15:34:20.421018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dabra24-trained-models/A10_best.pt\n",
      "/kaggle/input/dabra24-trained-models/BiLSTM_Full_best.pt\n",
      "/kaggle/input/dabra24-trained-models/A9_best.pt\n",
      "/kaggle/input/dabra24-trained-models/driver_behavior_route_anomaly_dataset_with_derived_features.csv\n",
      "/kaggle/input/dabra24-trained-models/A3_best.pt\n",
      "/kaggle/input/dabra24-trained-models/A6_best.pt\n",
      "/kaggle/input/dabra24-trained-models/A2_best.pt\n",
      "/kaggle/input/dabra24-trained-models/A7_best.pt\n",
      "/kaggle/input/dabra24-trained-models/A5_best.pt\n",
      "/kaggle/input/dabra24-trained-models/A8_best.pt\n",
      "/kaggle/input/dabra24-trained-models/A4_best.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "    for f in files:\n",
    "        print(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:34:20.432406Z",
     "iopub.status.busy": "2025-10-11T15:34:20.432147Z",
     "iopub.status.idle": "2025-10-11T15:34:20.516870Z",
     "shell.execute_reply": "2025-10-11T15:34:20.516150Z",
     "shell.execute_reply.started": "2025-10-11T15:34:20.432379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Environment ready.\n"
     ]
    }
   ],
   "source": [
    "# ================== Imports ==================\n",
    "import os, math, time, pickle, copy\n",
    "import numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from sklearn.metrics import average_precision_score, f1_score, mean_squared_error, precision_recall_curve, roc_curve, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, gc, time, math, random, json, pickle, shutil, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, precision_recall_curve, roc_curve, confusion_matrix,\n",
    "    f1_score, mean_squared_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from thop import profile\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# Globals\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Paths\n",
    "DATA_CSV = \"/kaggle/input/dabra24-trained-models/driver_behavior_route_anomaly_dataset_with_derived_features.csv\"\n",
    "\n",
    "# Directories\n",
    "OUT_DIR   = Path(\"./out\"); OUT_DIR.mkdir(exist_ok=True)\n",
    "MODEL_DIR = Path(\"./models\"); MODEL_DIR.mkdir(exist_ok=True)\n",
    "PLOT_DIR  = Path(\"./plots\"); PLOT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Config\n",
    "CFG = dict(\n",
    "    SEQ_LEN=60, STRIDE=5, SAMPLE_RATE_HZ=1,\n",
    "    BATCH_SIZE=256, EPOCHS=25, LR=5e-4, HIDDEN=256,\n",
    "    TCN_CHANNELS=64, DROPOUT=0.3, PATIENCE=5\n",
    ")\n",
    "SEED=42\n",
    "\n",
    "print(\"Environment ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) üì• Load & Inspect Data\n",
    "This block is robust to small naming differences and ensures required columns exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:34:20.519132Z",
     "iopub.status.busy": "2025-10-11T15:34:20.518878Z",
     "iopub.status.idle": "2025-10-11T15:34:21.399520Z",
     "shell.execute_reply": "2025-10-11T15:34:21.398875Z",
     "shell.execute_reply.started": "2025-10-11T15:34:20.519111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 120000\n",
      "Unique trips: 5\n",
      "count        5.000000\n",
      "mean     24000.000000\n",
      "std      20744.178424\n",
      "min      11800.000000\n",
      "25%      11945.000000\n",
      "50%      12204.000000\n",
      "75%      24163.000000\n",
      "max      59888.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def read_db(csv_path=DATA_CSV):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Normalize a few common names\n",
    "    rename_map = {\n",
    "        'lat':'latitude','lon':'longitude','long':'longitude','ts':'timestamp',\n",
    "        'driverid':'driver_id','vehicleid':'vehicle_id', 'tripid':'trip_id',\n",
    "        'anomaly_event':'anomalous_event', 'route_anom':'route_anomaly',\n",
    "        'route_deviation':'route_deviation_score'\n",
    "    }\n",
    "    df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "\n",
    "    # Timestamps\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    else:\n",
    "        raise ValueError(\"Missing 'timestamp' column in dataset.\")\n",
    "\n",
    "    # Labels (create safe fallbacks if absent)\n",
    "    for col in ['anomalous_event','route_anomaly','route_deviation_score']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0 if col != 'route_deviation_score' else 0.0\n",
    "\n",
    "    # Ensure IDs exist\n",
    "    if 'driver_id' not in df.columns:\n",
    "        df['driver_id'] = 0\n",
    "    if 'vehicle_id' not in df.columns:\n",
    "        df['vehicle_id'] = 0\n",
    "\n",
    "    # ‚úÖ Trip assignment logic\n",
    "    if 'trip_id' not in df.columns or df['trip_id'].nunique() >= len(df):\n",
    "        # If trip_id is missing OR every row is unique\n",
    "        if df['driver_id'].nunique() > 1:\n",
    "            # Group by driver\n",
    "            df['trip_id'] = df['driver_id'].astype(str)\n",
    "        elif df['vehicle_id'].nunique() > 1:\n",
    "            # Fallback: group by vehicle\n",
    "            df['trip_id'] = df['vehicle_id'].astype(str)\n",
    "        else:\n",
    "            # Last resort: treat all rows as one trip\n",
    "            df['trip_id'] = \"trip0\"\n",
    "\n",
    "    return df\n",
    "df_raw = read_db()\n",
    "print(\"Rows:\", len(df_raw))\n",
    "print(\"Unique trips:\", df_raw['trip_id'].nunique())\n",
    "print(df_raw.groupby('trip_id').size().describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) üß≠ Feature Groups & Light Engineering\n",
    "We organize columns into **kinematics**, **GPS**, **context** (weather/road/traffic), **map-aware**, and **trip statics**, then derive a few helpful signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:34:21.400350Z",
     "iopub.status.busy": "2025-10-11T15:34:21.400169Z",
     "iopub.status.idle": "2025-10-11T15:34:21.557451Z",
     "shell.execute_reply": "2025-10-11T15:34:21.556873Z",
     "shell.execute_reply.started": "2025-10-11T15:34:21.400335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups: {'kinematics': 10, 'gps': 2, 'context': 3, 'mapaware': 2, 'trip_static': 2, 'quality': 0}\n"
     ]
    }
   ],
   "source": [
    "def find_cols(df):\n",
    "    kinematics = [c for c in df.columns if c.lower() in\n",
    "                  ['speed','acceleration','rpm','steering_angle','heading','brake_usage',\n",
    "                   'lane_deviation','acceleration_variation','behavioral_consistency_index','turn_rate','yaw_rate','jerk']]\n",
    "    gps = [c for c in df.columns if c.lower() in ['latitude','longitude','bearing','altitude']]\n",
    "    context = [c for c in df.columns if c.lower() in ['weather_conditions','road_type','traffic_condition']]\n",
    "    mapaware = [c for c in df.columns if 'geofencing' in c.lower() or 'curvature' in c.lower()]\n",
    "    trip_static = [c for c in df.columns if c.lower() in ['trip_duration','trip_distance']]\n",
    "    quality = [c for c in df.columns if c.lower() in ['signal_quality','gps_accuracy']]\n",
    "    return dict(kinematics=kinematics, gps=gps, context=context, mapaware=mapaware,\n",
    "                trip_static=trip_static, quality=quality)\n",
    "\n",
    "def add_derived_features(df):\n",
    "    df = df.sort_values(['trip_id','timestamp']).copy()\n",
    "    # heading deltas ‚Üí turn intensity\n",
    "    if 'heading' in df.columns:\n",
    "        df['d_heading'] = df.groupby('trip_id')['heading'].diff().fillna(0)\n",
    "        df['turn_intensity'] = df['d_heading'].abs()\n",
    "    # jerk from acceleration\n",
    "    if 'acceleration' in df.columns:\n",
    "        df['jerk'] = df.groupby('trip_id')['acceleration'].diff().fillna(0)\n",
    "    # curvature proxy if missing\n",
    "    if 'curvature' not in df.columns and {'latitude','longitude'}.issubset(df.columns):\n",
    "        for ax in ['latitude','longitude']:\n",
    "            df[f'd_{ax}'] = df.groupby('trip_id')[ax].diff().fillna(0)\n",
    "        df['curvature'] = np.hypot(df['d_latitude'], df['d_longitude']).rolling(3, min_periods=1).mean()\n",
    "        df.drop(columns=[c for c in ['d_latitude','d_longitude'] if c in df.columns], inplace=True)\n",
    "    return df\n",
    "\n",
    "df = add_derived_features(df_raw)\n",
    "COLS = find_cols(df)\n",
    "print(\"Groups:\", {k:len(v) for k,v in COLS.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) üß± Windowing into Sequences\n",
    "We convert per-second telemetry into sliding windows (default **T=60s**, stride **5s**).  \n",
    "Colored highlights explain ablations in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:34:21.558417Z",
     "iopub.status.busy": "2025-10-11T15:34:21.558166Z",
     "iopub.status.idle": "2025-10-11T15:34:21.579546Z",
     "shell.execute_reply": "2025-10-11T15:34:21.578923Z",
     "shell.execute_reply.started": "2025-10-11T15:34:21.558398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 120000\n",
      "Unique trips: 5\n",
      "Per-trip length stats:\n",
      "count        5.000000\n",
      "mean     24000.000000\n",
      "std      20744.178424\n",
      "min      11800.000000\n",
      "25%      11945.000000\n",
      "50%      12204.000000\n",
      "75%      24163.000000\n",
      "max      59888.000000\n",
      "dtype: float64\n",
      "Timestamp range: 2023-01-01 00:00:00 ‚Üí 2023-01-02 09:19:59\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Unique trips:\", df['trip_id'].nunique())\n",
    "print(\"Per-trip length stats:\")\n",
    "print(df.groupby('trip_id').size().describe())\n",
    "print(\"Timestamp range:\", df['timestamp'].min(), \"‚Üí\", df['timestamp'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:34:21.580476Z",
     "iopub.status.busy": "2025-10-11T15:34:21.580253Z",
     "iopub.status.idle": "2025-10-11T15:34:21.596446Z",
     "shell.execute_reply": "2025-10-11T15:34:21.595811Z",
     "shell.execute_reply.started": "2025-10-11T15:34:21.580439Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==== SEQUENCE BUILDER WITH SAFETY ====\n",
    "def make_sequences(df, seq_len=60, stride=5, sample_hz=1, \n",
    "                   ablation=None, short_history=False, min_len=10):\n",
    "    df_proc = df.copy()\n",
    "\n",
    "    # One-hot encode categorical context\n",
    "    for cat in [c for c in ['weather_conditions','road_type','traffic_condition'] if c in df_proc.columns]:\n",
    "        df_proc[cat] = df_proc[cat].astype(str).fillna(\"unk\")\n",
    "    context_cols = [c for c in ['weather_conditions','road_type','traffic_condition'] if c in df_proc.columns]\n",
    "    oh = pd.get_dummies(df_proc[context_cols], prefix=context_cols) if context_cols else pd.DataFrame(index=df_proc.index)\n",
    "    df_proc = pd.concat([df_proc.drop(columns=context_cols), oh], axis=1)\n",
    "\n",
    "    # Time-of-day encoding\n",
    "    df_proc['sec_of_day'] = df_proc['timestamp'].dt.hour*3600 + df_proc['timestamp'].dt.minute*60 + df_proc['timestamp'].dt.second\n",
    "    df_proc['sin_t'] = np.sin(2*np.pi*df_proc['sec_of_day']/86400)\n",
    "    df_proc['cos_t'] = np.cos(2*np.pi*df_proc['sec_of_day']/86400)\n",
    "\n",
    "    # Dynamic features\n",
    "    dyn_cols = COLS['kinematics'] + COLS['gps'] + ['turn_intensity','jerk','curvature','sin_t','cos_t']\n",
    "    dyn_cols = [c for c in dyn_cols if c in df_proc.columns]\n",
    "\n",
    "    # A5 jitter\n",
    "    if ablation == \"A5-jitter\":\n",
    "        ctx_like = [c for c in df_proc.columns if any(k in c.lower() for k in ['weather_', 'road_', 'traffic_'])]\n",
    "        for c in ctx_like:\n",
    "            df_proc[c] = df_proc.groupby('trip_id')[c].shift(1)\n",
    "\n",
    "    # A6 short history\n",
    "    if short_history:\n",
    "        seq_len = 20\n",
    "\n",
    "    # A2/A8 feature drop\n",
    "    drop_cols = []\n",
    "    if ablation == \"A2-nocontext\":\n",
    "        drop_cols += [c for c in df_proc.columns if any(k in c.lower() for k in ['weather_', 'road_', 'traffic_'])]\n",
    "    if ablation == \"A8-mapfree\":\n",
    "        drop_cols += [c for c in df_proc.columns if 'geofencing' in c.lower() or 'curvature' in c.lower()]\n",
    "    df_proc = df_proc.drop(columns=[c for c in set(drop_cols) if c in df_proc.columns], errors='ignore')\n",
    "\n",
    "    dyn_cols = [c for c in dyn_cols if c in df_proc.columns]\n",
    "    dyn_cols = list(dict.fromkeys(dyn_cols + [c for c in df_proc.columns if any(p in c for p in ['weather_','road_','traffic_'])]))\n",
    "\n",
    "    static_cols = [c for c in COLS['trip_static'] if c in df_proc.columns]\n",
    "    if 'behavioral_consistency_index' in df_proc.columns and 'behavioral_consistency_index' not in static_cols:\n",
    "        static_cols.append('behavioral_consistency_index')\n",
    "\n",
    "    labels_A = 'anomalous_event'\n",
    "    labels_B = 'route_anomaly'\n",
    "    labels_C = 'route_deviation_score'\n",
    "\n",
    "    # Slide per trip\n",
    "    seqs, statics, yA, yB, yC, meta = [], [], [], [], [], []\n",
    "    skipped = 0\n",
    "    for trip, df_t in df_proc.groupby('trip_id', sort=False):\n",
    "        df_t = df_t.sort_values('timestamp').copy()\n",
    "        df_t = df_t.set_index('timestamp').resample(f\"{int(1000/sample_hz)}L\").nearest(limit=1).ffill().bfill().reset_index()\n",
    "        n = len(df_t)\n",
    "        if n < seq_len: \n",
    "            skipped += 1\n",
    "            continue\n",
    "        for start in range(0, n - seq_len + 1, stride):\n",
    "            w = df_t.iloc[start:start+seq_len]\n",
    "            X = w[dyn_cols].astype(float).values if dyn_cols else np.zeros((seq_len,0))\n",
    "            s = w[static_cols].mean().values if static_cols else np.zeros((0,))\n",
    "            a = int(w[labels_A].max())\n",
    "            b = int(w[labels_B].max())\n",
    "            c = float(w[labels_C].mean())\n",
    "            seqs.append(X); statics.append(s); yA.append(a); yB.append(b); yC.append(c)\n",
    "            meta.append(dict(trip_id=trip, t0=w['timestamp'].iloc[0], t1=w['timestamp'].iloc[-1]))\n",
    "    if skipped > 0:\n",
    "        print(f\"[make_sequences] ‚ö†Ô∏è Skipped {skipped} trips with length < {seq_len}\")\n",
    "    print(f\"[make_sequences] Generated {len(seqs)} windows (seq_len={seq_len}, stride={stride})\")\n",
    "\n",
    "    return dict(X=seqs, S=statics, yA=np.array(yA), yB=np.array(yB), yC=np.array(yC), meta=meta,\n",
    "                dyn_cols=dyn_cols, static_cols=static_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:34:21.597474Z",
     "iopub.status.busy": "2025-10-11T15:34:21.597242Z",
     "iopub.status.idle": "2025-10-11T15:34:21.616143Z",
     "shell.execute_reply": "2025-10-11T15:34:21.615506Z",
     "shell.execute_reply.started": "2025-10-11T15:34:21.597432Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def subsample_dict(d, frac=0.4, seed=42):\n",
    "    \"\"\"Safely subsample dictionary of sequences.\"\"\"\n",
    "    n = len(d['X'])\n",
    "    if n == 0:\n",
    "        print(\"[subsample_dict] ‚ö†Ô∏è No data to subsample (n=0). Returning original dict.\")\n",
    "        return d\n",
    "    \n",
    "    take = max(1, int(frac * n))\n",
    "    idx = np.random.default_rng(seed).choice(n, take, replace=False)\n",
    "\n",
    "    return {\n",
    "        k: (d[k][idx] if isinstance(d[k], np.ndarray) else [d[k][i] for i in idx])\n",
    "        for k in ['X','S','yA','yB','yC','meta']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:34:21.617185Z",
     "iopub.status.busy": "2025-10-11T15:34:21.616945Z",
     "iopub.status.idle": "2025-10-11T15:36:48.835928Z",
     "shell.execute_reply": "2025-10-11T15:36:48.835131Z",
     "shell.execute_reply.started": "2025-10-11T15:34:21.617169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_sequences] Generated 119930 windows (seq_len=60, stride=5)\n",
      "After subsample: 47972\n"
     ]
    }
   ],
   "source": [
    "# Step 1: make sequences (auto-adjust ensures >0 windows if possible)\n",
    "data_full = make_sequences(df, seq_len=CFG['SEQ_LEN'], stride=CFG['STRIDE'], sample_hz=CFG['SAMPLE_RATE_HZ'])\n",
    "\n",
    "# Step 2: subsample if needed\n",
    "data_full = subsample_dict(data_full, frac=0.4, seed=SEED)\n",
    "print(\"After subsample:\", len(data_full['X']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:36:48.848965Z",
     "iopub.status.busy": "2025-10-11T15:36:48.848708Z",
     "iopub.status.idle": "2025-10-11T15:36:48.855134Z",
     "shell.execute_reply": "2025-10-11T15:36:48.854430Z",
     "shell.execute_reply.started": "2025-10-11T15:36:48.848945Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==== AUTO-FIX if NO WINDOWS ====\n",
    "def rebuild_sequences_auto(df, base_stride=5):\n",
    "    trip_len = df.groupby('trip_id').size()\n",
    "    med = int(trip_len.median()) if len(trip_len) else 60\n",
    "    T0  = max(10, min(60, max(10, med // 2)))\n",
    "    stride = max(1, min(base_stride, T0 // 5))\n",
    "\n",
    "    for T_try in [T0, 40, 30, 20, 10]:\n",
    "        seqs = make_sequences(df, seq_len=T_try, stride=stride, sample_hz=CFG['SAMPLE_RATE_HZ'])\n",
    "        if len(seqs['X']) > 0:\n",
    "            CFG['SEQ_LEN'] = T_try\n",
    "            CFG['STRIDE']  = stride\n",
    "            print(f\"[Auto] Using SEQ_LEN={T_try}, STRIDE={stride} ‚Üí windows={len(seqs['X'])}\")\n",
    "            return seqs\n",
    "\n",
    "    print(\"[Auto] ‚ö†Ô∏è Could not create windows with T>=10 ‚Üí fallback to T=1\")\n",
    "    seqs = make_sequences(df, seq_len=1, stride=1, sample_hz=CFG['SAMPLE_RATE_HZ'])\n",
    "    CFG['SEQ_LEN'] = 1\n",
    "    CFG['STRIDE']  = 1\n",
    "    return seqs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) ‚úÇÔ∏è Split by Driver (No Leakage)\n",
    "We split train/val/test **by driver** so windows from the same driver don‚Äôt leak into other sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:36:48.856118Z",
     "iopub.status.busy": "2025-10-11T15:36:48.855869Z",
     "iopub.status.idle": "2025-10-11T15:36:48.871698Z",
     "shell.execute_reply": "2025-10-11T15:36:48.871082Z",
     "shell.execute_reply.started": "2025-10-11T15:36:48.856101Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==== SPLIT with FEATURE METADATA ====\n",
    "def split_dict(d, idx):\n",
    "    out = {\n",
    "        k: (d[k][idx] if isinstance(d[k], np.ndarray) else [d[k][i] for i in idx])\n",
    "        for k in ['X','S','yA','yB','yC','meta']\n",
    "    }\n",
    "    out['dyn_cols'] = d.get('dyn_cols', [])\n",
    "    out['static_cols'] = d.get('static_cols', [])\n",
    "    return out\n",
    "\n",
    "\n",
    "# ==== STACK UTILITY ====\n",
    "def stack_X(X_list):\n",
    "    if len(X_list) == 0:\n",
    "        return np.zeros((0,0,0), dtype=np.float32)\n",
    "    T = len(X_list[0]); F = X_list[0].shape[1] if T > 0 else 0\n",
    "    out = np.zeros((len(X_list), T, F), dtype=np.float32)\n",
    "    for i,x in enumerate(X_list): out[i] = x\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) üìè Scaling & PyTorch Datasets\n",
    "We standardize dynamic features using **train only** then wrap them into PyTorch datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:36:48.872506Z",
     "iopub.status.busy": "2025-10-11T15:36:48.872263Z",
     "iopub.status.idle": "2025-10-11T15:36:50.564227Z",
     "shell.execute_reply": "2025-10-11T15:36:50.563395Z",
     "shell.execute_reply.started": "2025-10-11T15:36:48.872482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split sizes: 28803 9681 9488\n",
      "‚úÖ Data ready: (28803, 60, 26) (28803, 0) | Dyn: 0 | Static: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# ============== GROUPED SPLIT (driver_id or trip_id) ==============\n",
    "drivers = df[['trip_id','driver_id']].drop_duplicates()\n",
    "trip2driver = dict(zip(drivers['trip_id'], drivers['driver_id']))\n",
    "\n",
    "groups_driver = np.array([trip2driver.get(m['trip_id'], -1) for m in data_full['meta']])\n",
    "n_unique_drivers = pd.Series(groups_driver).nunique()\n",
    "\n",
    "if n_unique_drivers < 2:\n",
    "    print(\"[Warn] Only one driver ‚Üí grouping by trip_id instead.\")\n",
    "    groups = np.array([m['trip_id'] for m in data_full['meta']])\n",
    "else:\n",
    "    groups = groups_driver\n",
    "\n",
    "n_samples = len(groups)\n",
    "if n_samples == 0:\n",
    "    raise RuntimeError(\"‚ùå No sequences created. Check your preprocessing.\")\n",
    "\n",
    "if pd.Series(groups).nunique() < 2:\n",
    "    # fallback to random split\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    idx_all = np.arange(n_samples); rng.shuffle(idx_all)\n",
    "    n_test = max(1, int(0.2*n_samples)); n_val = max(1, int(0.1*(n_samples-n_test)))\n",
    "    idx_test = idx_all[:n_test]; idx_val = idx_all[n_test:n_test+n_val]; idx_train = idx_all[n_test+n_val:]\n",
    "else:\n",
    "    gss = GroupShuffleSplit(test_size=0.2, random_state=SEED)\n",
    "    idx_train, idx_test = next(gss.split(np.arange(n_samples), groups=groups))\n",
    "    gss_val = GroupShuffleSplit(test_size=0.125, random_state=SEED)  # ~10% total for val\n",
    "    idx_train, idx_val = next(gss_val.split(idx_train, groups=groups[idx_train]))\n",
    "\n",
    "print(\"‚úÖ Split sizes:\", len(idx_train), len(idx_val), len(idx_test))\n",
    "\n",
    "# ==== APPLY ====\n",
    "if len(data_full['X']) == 0:\n",
    "    data_full = rebuild_sequences_auto(df)\n",
    "\n",
    "train = split_dict(data_full, idx_train)\n",
    "val   = split_dict(data_full, idx_val)\n",
    "test  = split_dict(data_full, idx_test)\n",
    "\n",
    "dyn_cols = train['dyn_cols']\n",
    "static_cols = train['static_cols']\n",
    "\n",
    "# Scale features\n",
    "X_train = stack_X(train['X']); X_val = stack_X(val['X']); X_test = stack_X(test['X'])\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "if X_train.shape[-1] > 0:\n",
    "    scaler.fit(X_train.reshape(-1, X_train.shape[-1]))\n",
    "    def transform(X):\n",
    "        if X.shape[-1]==0: return X\n",
    "        Xr = X.reshape(-1, X.shape[-1]); Xr = scaler.transform(Xr)\n",
    "        return Xr.reshape(X.shape)\n",
    "else:\n",
    "    transform = lambda x: x\n",
    "X_train, X_val, X_test = transform(X_train), transform(X_val), transform(X_test)\n",
    "\n",
    "# Static features\n",
    "S_train = np.array(train['S'], dtype=np.float32) if static_cols else np.zeros((len(train['X']),0), np.float32)\n",
    "S_val   = np.array(val['S'],   dtype=np.float32) if static_cols else np.zeros((len(val['X']),0), np.float32)\n",
    "S_test  = np.array(test['S'],  dtype=np.float32) if static_cols else np.zeros((len(test['X']),0), np.float32)\n",
    "\n",
    "# Labels\n",
    "yA_train, yB_train, yC_train = train['yA'], train['yB'], train['yC']\n",
    "yA_val,   yB_val,   yC_val   = val['yA'],   val['yB'],   val['yC']\n",
    "yA_test,  yB_test,  yC_test  = test['yA'],  test['yB'],  test['yC']\n",
    "\n",
    "# ==== TORCH DATASETS ====\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, S, yA, yB, yC):\n",
    "        self.X, self.S = torch.tensor(X), torch.tensor(S)\n",
    "        self.yA = torch.tensor(yA).float()\n",
    "        self.yB = torch.tensor(yB).float()\n",
    "        self.yC = torch.tensor(yC).float()\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.S[i], self.yA[i], self.yB[i], self.yC[i]\n",
    "\n",
    "ds_train = SeqDataset(X_train, S_train, yA_train, yB_train, yC_train)\n",
    "ds_val   = SeqDataset(X_val,   S_val,   yA_val,   yB_val,   yC_val)\n",
    "ds_test  = SeqDataset(X_test,  S_test,  yA_test,  yB_test,  yC_test)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=CFG['BATCH_SIZE'], shuffle=True,  num_workers=4, pin_memory=True)\n",
    "dl_val   = DataLoader(ds_val,   batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4, pin_memory=True)\n",
    "dl_test  = DataLoader(ds_test,  batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(\"‚úÖ Data ready:\", X_train.shape, S_train.shape, \"| Dyn:\", len(dyn_cols), \"| Static:\", len(static_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) üß† Models (Bi-LSTM, TCN-Small, Gating)\n",
    "- <span style=\"color:#6C5CE7\">Gating</span> learns reliability weights per feature (can be disabled in A3).  \n",
    "- <span style=\"color:#E17055\">Bi-LSTM</span> is our main sequence model.  \n",
    "- <span style=\"color:#0984E3\">TCN-Small</span> is an efficient edge variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:36:50.565501Z",
     "iopub.status.busy": "2025-10-11T15:36:50.565173Z",
     "iopub.status.idle": "2025-10-11T15:36:50.583152Z",
     "shell.execute_reply": "2025-10-11T15:36:50.582487Z",
     "shell.execute_reply.started": "2025-10-11T15:36:50.565452Z"
    }
   },
   "outputs": [],
   "source": [
    "# ================== Models ==================\n",
    "class GateLayer(nn.Module):\n",
    "    def __init__(self, in_feats=None):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_feats, in_feats) if in_feats else None\n",
    "    def forward(self, x):  # [B,T,F]\n",
    "        F = x.size(-1)\n",
    "        if self.fc is None or self.fc.in_features != F:\n",
    "            self.fc = nn.Linear(F, F).to(x.device)\n",
    "        g = torch.sigmoid(self.fc(x.mean(1)))\n",
    "        return x * g.unsqueeze(1)\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, in_feats, static_feats=0, hidden=128, layers=2, dropout=0.1, gated=True):\n",
    "        super().__init__()\n",
    "        self.gated = gated and in_feats>0\n",
    "        self.gate = GateLayer(in_feats) if self.gated else nn.Identity()\n",
    "        self.lstm = nn.LSTM(input_size=in_feats, hidden_size=hidden, num_layers=layers,\n",
    "                            batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        emb = hidden*2\n",
    "        self.fc_context = nn.Linear(static_feats, hidden) if static_feats>0 else None\n",
    "        head_in = emb + (hidden if self.fc_context else 0)\n",
    "        self.headA, self.headB, self.headC = nn.Linear(head_in,1), nn.Linear(head_in,1), nn.Linear(head_in,1)\n",
    "    def forward(self, x, s):\n",
    "        x = self.gate(x) if self.gated else x\n",
    "        out,_ = self.lstm(x); h = out.mean(1)\n",
    "        if self.fc_context: h = torch.cat([h, torch.relu(self.fc_context(s))], dim=1)\n",
    "        return self.headA(h).squeeze(1), self.headB(h).squeeze(1), self.headC(h).squeeze(1)\n",
    "\n",
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, d=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, k, padding=d*(k-1)//2, dilation=d)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "    def forward(self, x): return torch.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, in_feats, static_feats=0, ch=64, layers=3, gated=True):\n",
    "        super().__init__()\n",
    "        self.gated = gated and in_feats>0\n",
    "        self.gate = GateLayer(in_feats) if self.gated else nn.Identity()\n",
    "        chans = [in_feats, ch, ch, ch][:layers+1]\n",
    "        blocks = [TCNBlock(chans[i], chans[i+1], d=2**i) for i in range(layers)]\n",
    "        self.net = nn.Sequential(*blocks)\n",
    "        self.fc_context = nn.Linear(static_feats, ch) if static_feats>0 else None\n",
    "        head_in = ch + (ch if self.fc_context else 0)\n",
    "        self.headA, self.headB, self.headC = nn.Linear(head_in,1), nn.Linear(head_in,1), nn.Linear(head_in,1)\n",
    "    def forward(self, x, s):\n",
    "        x = self.gate(x) if self.gated else x\n",
    "        z = self.net(x.permute(0,2,1)).mean(-1)\n",
    "        if self.fc_context: z = torch.cat([z, torch.relu(self.fc_context(s))], dim=1)\n",
    "        return self.headA(z).squeeze(1), self.headB(z).squeeze(1), self.headC(z).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) üìê Losses & Metrics\n",
    "We compute:\n",
    "- **PR-AUC (A/B)**, **F1 (A)**, **RMSE (C)**, **ECE** (calibration),  \n",
    "- **TTD** (time-to-detection), **FP/h**, **Latency (ms)**, **FLOPs (M)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:36:50.584556Z",
     "iopub.status.busy": "2025-10-11T15:36:50.584285Z",
     "iopub.status.idle": "2025-10-11T15:36:50.608958Z",
     "shell.execute_reply": "2025-10-11T15:36:50.608316Z",
     "shell.execute_reply.started": "2025-10-11T15:36:50.584532Z"
    }
   },
   "outputs": [],
   "source": [
    "# ================== Losses / Metrics ==================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0): super().__init__(); self.alpha,self.gamma=alpha,gamma\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        ce = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        p_t = probs*targets + (1-probs)*(1-targets)\n",
    "        loss = ce * ((1-p_t)**self.gamma) * (self.alpha*targets + (1-self.alpha)*(1-targets))\n",
    "        return loss.mean()\n",
    "\n",
    "def ece_score(y_true, y_prob, n_bins=15):\n",
    "    y_true, y_prob = np.asarray(y_true).astype(int), np.asarray(y_prob)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins+1); inds = np.digitize(y_prob, bins) - 1\n",
    "    ece=0.0\n",
    "    for b in range(n_bins):\n",
    "        mask = inds==b\n",
    "        if not np.any(mask): continue\n",
    "        acc, conf = y_true[mask].mean(), y_prob[mask].mean()\n",
    "        ece += mask.mean() * abs(acc-conf)\n",
    "    return float(ece)\n",
    "\n",
    "def best_f1_threshold(y_true,y_prob):\n",
    "    ps, rs, ts = precision_recall_curve(y_true,y_prob); f1s = 2*ps*rs/(ps+rs+1e-9)\n",
    "    i = np.nanargmax(f1s); return float(ts[i]) if i<len(ts) else 0.5\n",
    "\n",
    "def ttd_and_fprate(meta, y_true, y_prob, threshold=0.5, window_seconds=5):\n",
    "    \"\"\"Compute average time-to-detection (s) and false positives per hour.\"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = (np.asarray(y_prob) >= threshold).astype(int)\n",
    "\n",
    "    # === FP/h ===\n",
    "    fp = ((y_pred == 1) & (y_true == 0)).sum()\n",
    "    hours = (len(y_true) * window_seconds) / 3600.0\n",
    "    fp_rate = fp / max(hours, 1e-6)\n",
    "\n",
    "    # === TTD (s) ===\n",
    "    ttd_list = []\n",
    "    pos_idx = np.where(y_true == 1)[0]\n",
    "    if len(pos_idx) > 0:\n",
    "        # For each true positive segment, find first detection afterwards\n",
    "        for i in pos_idx:\n",
    "            detect_idx = np.where((y_pred[i:] == 1))[0]\n",
    "            if len(detect_idx) > 0:\n",
    "                delay_s = detect_idx[0] * window_seconds\n",
    "                ttd_list.append(delay_s)\n",
    "        ttd_s = np.mean(ttd_list) if len(ttd_list) > 0 else np.nan\n",
    "    else:\n",
    "        ttd_s = np.nan\n",
    "\n",
    "    return ttd_s, fp_rate\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from thop import profile\n",
    "\n",
    "def measure_latency_flops(model, in_feats, static_feats, seq_len=60, runs=30):\n",
    "    \"\"\"Compute model FLOPs (M) and latency (ms) ‚Äî with GPU or CPU fallback.\"\"\"\n",
    "    model = model.to(device).eval()\n",
    "    X = torch.randn(1, seq_len, in_feats).to(device)\n",
    "    S = torch.randn(1, static_feats).to(device)\n",
    "\n",
    "    # ===== FLOPs estimation =====\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            flops, params = profile(model, inputs=(X, S), verbose=False)\n",
    "        flops_m = flops / 1e6  # millions\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] FLOPs measurement failed: {e}\")\n",
    "        flops_m = np.nan\n",
    "\n",
    "    # ===== Latency measurement =====\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        # Warm-up runs\n",
    "        for _ in range(5):\n",
    "            _ = model(X, S)\n",
    "\n",
    "        if device.type == \"cuda\":\n",
    "            starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "            for _ in range(runs):\n",
    "                starter.record()\n",
    "                _ = model(X, S)\n",
    "                ender.record()\n",
    "                torch.cuda.synchronize()\n",
    "                timings.append(starter.elapsed_time(ender))  # ms\n",
    "            latency_ms = float(np.mean(timings))\n",
    "        else:\n",
    "            # CPU fallback\n",
    "            for _ in range(runs):\n",
    "                t0 = time.time()\n",
    "                _ = model(X, S)\n",
    "                t1 = time.time()\n",
    "                timings.append((t1 - t0) * 1000)  # convert to ms\n",
    "            latency_ms = float(np.mean(timings))\n",
    "\n",
    "    return flops_m, latency_ms\n",
    "\n",
    "\n",
    "def save_curves(ablation_code, y, p, tag):\n",
    "    # PR\n",
    "    P,R,thr = precision_recall_curve(y,p)\n",
    "    plt.figure(); plt.plot(R,P); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"{ablation_code} PR {tag}\")\n",
    "    plt.grid(True, alpha=.3); plt.tight_layout(); plt.savefig(PLOT_DIR/f\"{ablation_code}_PR_{tag}.png\"); plt.close()\n",
    "    # ROC\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y,p)\n",
    "        plt.figure(); plt.plot(fpr,tpr); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"{ablation_code} ROC {tag}\")\n",
    "        plt.grid(True, alpha=.3); plt.tight_layout(); plt.savefig(PLOT_DIR/f\"{ablation_code}_ROC_{tag}.png\"); plt.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Reliability\n",
    "    bins = np.linspace(0,1,11); inds = np.digitize(p,bins)-1\n",
    "    acc=[]; conf=[]\n",
    "    for b in range(10):\n",
    "        msk=inds==b\n",
    "        if msk.any():\n",
    "            acc.append(y[msk].mean()); conf.append(p[msk].mean())\n",
    "    plt.figure(); plt.plot([0,1],[0,1],'--',alpha=.4); plt.plot(conf, acc, marker='o')\n",
    "    plt.xlabel(\"Confidence\"); plt.ylabel(\"Accuracy\"); plt.title(f\"{ablation_code} Reliability {tag}\")\n",
    "    plt.grid(True, alpha=.3); plt.tight_layout(); plt.savefig(PLOT_DIR/f\"{ablation_code}_Reliability_{tag}.png\"); plt.close()\n",
    "\n",
    "def save_confusion(ablation_code, y, p, tag, thr):\n",
    "    cm = confusion_matrix(y, (p>=thr).astype(int))\n",
    "    plt.figure(); plt.imshow(cm, cmap=\"Blues\"); plt.title(f\"{ablation_code} Confusion {tag}\\n(thr={thr:.3f})\")\n",
    "    plt.colorbar(); plt.xticks([0,1],[\"Pred 0\",\"Pred 1\"]); plt.yticks([0,1],[\"True 0\",\"True 1\"])\n",
    "    for (i,j),v in np.ndenumerate(cm):\n",
    "        plt.text(j,i, int(v), ha=\"center\", va=\"center\")\n",
    "    plt.tight_layout(); plt.savefig(PLOT_DIR/f\"{ablation_code}_Confusion_{tag}.png\"); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) üèÉ Training & Evaluation Utilities\n",
    "Includes early stopping, metric computation, latency/FLOPs estimation, and plot saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:36:50.609794Z",
     "iopub.status.busy": "2025-10-11T15:36:50.609584Z",
     "iopub.status.idle": "2025-10-11T15:36:50.626416Z",
     "shell.execute_reply": "2025-10-11T15:36:50.625811Z",
     "shell.execute_reply.started": "2025-10-11T15:36:50.609779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =================== FIX: use per-split loaders in training ===================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:36:50.627316Z",
     "iopub.status.busy": "2025-10-11T15:36:50.627128Z",
     "iopub.status.idle": "2025-10-11T15:36:50.647000Z",
     "shell.execute_reply": "2025-10-11T15:36:50.646393Z",
     "shell.execute_reply.started": "2025-10-11T15:36:50.627294Z"
    }
   },
   "outputs": [],
   "source": [
    "# ================== Training Loop ==================\n",
    "def make_loaders(ds_tr, ds_va, batch):\n",
    "    return (DataLoader(ds_tr,batch,True,4,pin_memory=True),\n",
    "            DataLoader(ds_va,batch,False,4,pin_memory=True))\n",
    "\n",
    "def train_model(model, ablation_name, loss_mode, dl_tr, dl_va, yA_for_weights, yB_for_weights):\n",
    "    model = model.to(device); opt = AdamW(model.parameters(), lr=CFG['LR'])\n",
    "    scaler = GradScaler(enabled=(device.type==\"cuda\"))\n",
    "    cwA = compute_class_weight('balanced', classes=np.array([0,1]), y=yA_for_weights).tolist()\n",
    "    cwB = compute_class_weight('balanced', classes=np.array([0,1]), y=yB_for_weights).tolist()\n",
    "    posA,posB = torch.tensor(cwA[1]/cwA[0],device=device),torch.tensor(cwB[1]/cwB[0],device=device)\n",
    "    focal = FocalLoss().to(device)\n",
    "    best_val=float(\"inf\"); bad=0\n",
    "\n",
    "    for ep in range(1, CFG['EPOCHS']+1):\n",
    "        model.train(); tr_loss=0.0; opt.zero_grad()\n",
    "        for i,(X,S,ya,yb,yc) in enumerate(dl_tr):\n",
    "            X,S,ya,yb,yc = X.to(device),S.to(device),ya.to(device),yb.to(device),yc.to(device)\n",
    "            with autocast(enabled=(device.type==\"cuda\")):\n",
    "                a,b,c = model(X,S)\n",
    "                la = focal(a,ya) if loss_mode=='focal' else F.binary_cross_entropy_with_logits(a,ya,pos_weight=posA)\n",
    "                lb = focal(b,yb) if loss_mode=='focal' else F.binary_cross_entropy_with_logits(b,yb,pos_weight=posB)\n",
    "                lc = F.smooth_l1_loss(c,yc)\n",
    "                loss=(la+lb+0.5*lc)/2\n",
    "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update(); opt.zero_grad()\n",
    "            tr_loss += loss.item()\n",
    "        # Validation\n",
    "        model.eval(); vl=0.0;n=0;yA,yB,pa,pb=[],[],[],[]\n",
    "        with torch.no_grad(), autocast(enabled=(device.type==\"cuda\")):\n",
    "            for X,S,ya,yb,yc in dl_va:\n",
    "                X,S,ya,yb,yc = X.to(device),S.to(device),ya.to(device),yb.to(device),yc.to(device)\n",
    "                a,b,c = model(X,S)\n",
    "                la=F.binary_cross_entropy_with_logits(a,ya); lb=F.binary_cross_entropy_with_logits(b,yb); lc=F.smooth_l1_loss(c,yc)\n",
    "                vl+=(la+lb+0.5*lc).item(); n+=1\n",
    "                yA.extend(ya.cpu().numpy()); pa.extend(torch.sigmoid(a).cpu().numpy())\n",
    "                yB.extend(yb.cpu().numpy()); pb.extend(torch.sigmoid(b).cpu().numpy())\n",
    "        vl/=max(1,n)\n",
    "        prA, f1A = average_precision_score(yA,pa), f1_score(yA,(np.array(pa)>=0.5).astype(int))\n",
    "        prB, f1B = average_precision_score(yB,pb), f1_score(yB,(np.array(pb)>=0.5).astype(int))\n",
    "        print(f\"[{ablation_name}] epoch {ep} train_loss={tr_loss/len(dl_tr):.4f} val_loss={vl:.4f} \"\n",
    "              f\"A: PR-AUC={prA:.3f} F1={f1A:.3f}  B: PR-AUC={prB:.3f} F1={f1B:.3f}\")\n",
    "        if vl<best_val: best_val=vl; bad=0; torch.save(model.state_dict(), MODEL_DIR/f\"{ablation_name}_best.pt\")\n",
    "        else: bad+=1; \n",
    "        if bad>=CFG['PATIENCE']: print(f\"üõë Early stopping at epoch {ep}\"); break\n",
    "    model.load_state_dict(torch.load(MODEL_DIR/f\"{ablation_name}_best.pt\")); return model.eval()\n",
    "\n",
    "# ================== Eval ==================\n",
    "def predict_model(model, ds, batch=CFG['BATCH_SIZE']):\n",
    "    dl = DataLoader(ds, batch_size=batch, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    pa, pb, pc = [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad(), autocast(enabled=(device.type==\"cuda\")):\n",
    "        for X, S, _, _, _ in dl:\n",
    "            X = X.to(device); S = S.to(device)\n",
    "            a, b, c = model(X, S)\n",
    "            pa.extend(torch.sigmoid(a).cpu().numpy())\n",
    "            pb.extend(torch.sigmoid(b).cpu().numpy())\n",
    "            pc.extend(c.cpu().numpy())\n",
    "    return np.array(pa), np.array(pb), np.array(pc)\n",
    "\n",
    "def eval_all(name, yA, yB, yC, pA, pB, pC, meta):\n",
    "    thA, thB = best_f1_threshold(yA, pA), best_f1_threshold(yB, pB)\n",
    "    ttd_s, fp_h = ttd_and_fprate(meta, yA, pA, threshold=thA)\n",
    "    return dict(\n",
    "        precision_auc_A=average_precision_score(yA, pA),\n",
    "        f1_A=f1_score(yA, (pA >= thA).astype(int)),\n",
    "        precision_auc_B=average_precision_score(yB, pB),\n",
    "        rmse_C=math.sqrt(mean_squared_error(yC, pC)),\n",
    "        ece=ece_score(yA, pA),\n",
    "        ttd_s=ttd_s,\n",
    "        fp_per_hour=fp_h\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) üå≥ A1 ‚Äî <span style=\"color:#6C5CE7\">GBM (No Mobility, Temporal-Agnostic)</span>\n",
    "Replace sequence DL with **static aggregates** (mean/std/min/max over window).  \n",
    "**Hypothesis:** PR-AUC drops; **TTD** increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:36:50.648142Z",
     "iopub.status.busy": "2025-10-11T15:36:50.647719Z",
     "iopub.status.idle": "2025-10-11T15:36:50.665125Z",
     "shell.execute_reply": "2025-10-11T15:36:50.664440Z",
     "shell.execute_reply.started": "2025-10-11T15:36:50.648126Z"
    }
   },
   "outputs": [],
   "source": [
    "# ================== GBM Baseline (A1) ==================\n",
    "def aggregate_for_gbm(split):\n",
    "    feats=[np.concatenate([X.mean(0),X.std(0),X.min(0),X.max(0)]) if X.shape[-1]>0 else np.zeros(4) for X in split['X']]\n",
    "    return np.array(feats,np.float32), np.array(split['yA']), np.array(split['yB']), np.array(split['yC'])\n",
    "\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def run_gbm(name=\"A1_GBM\", save_dir=\"models\"):\n",
    "    # Aggregate features and labels\n",
    "    Xtr, yAtr, yBtr, yCtr = aggregate_for_gbm(train)\n",
    "    Xva, yAva, yBva, yCva = aggregate_for_gbm(val)\n",
    "    Xte, yAte, yBte, yCte = aggregate_for_gbm(test)\n",
    "\n",
    "    # Define three LightGBM learners\n",
    "    gbmA = lgb.LGBMClassifier(\n",
    "        n_estimators=1000, learning_rate=0.05, num_leaves=64,\n",
    "        objective=\"binary\", random_state=SEED\n",
    "    )\n",
    "    gbmB = lgb.LGBMClassifier(\n",
    "        n_estimators=1000, learning_rate=0.05, num_leaves=64,\n",
    "        objective=\"binary\", random_state=SEED\n",
    "    )\n",
    "    gbrC = lgb.LGBMRegressor(\n",
    "        n_estimators=1000, learning_rate=0.05, num_leaves=64,\n",
    "        objective=\"regression\", random_state=SEED\n",
    "    )\n",
    "\n",
    "    # Train with early stopping\n",
    "    gbmA.fit(Xtr, yAtr, eval_set=[(Xva, yAva)], eval_metric=\"average_precision\",\n",
    "             callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(0)])\n",
    "    gbmB.fit(Xtr, yBtr, eval_set=[(Xva, yBva)], eval_metric=\"average_precision\",\n",
    "             callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(0)])\n",
    "    gbrC.fit(Xtr, yCtr, eval_set=[(Xva, yCva)], eval_metric=\"rmse\",\n",
    "             callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(0)])\n",
    "\n",
    "    # Predictions\n",
    "    pA = gbmA.predict_proba(Xte)[:, 1]\n",
    "    pB = gbmB.predict_proba(Xte)[:, 1]\n",
    "    pC = gbrC.predict(Xte)\n",
    "\n",
    "    # Evaluate\n",
    "    results = eval_all(\"A1\", yAte, yBte, yCte, pA, pB, pC, test['meta'])\n",
    "\n",
    "    # --- Save models in unified .pt checkpoint ---\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model_path = os.path.join(save_dir, \"A1_best.pt\")\n",
    "    torch.save({\n",
    "        \"model_A\": gbmA,\n",
    "        \"model_B\": gbmB,\n",
    "        \"model_C\": gbrC,\n",
    "        \"results\": results\n",
    "    }, model_path)\n",
    "\n",
    "    print(f\"‚úÖ Saved baseline LightGBM ensemble to {model_path}\")\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) üß™ Ablations A2‚ÄìA10 (one-by-one)\n",
    "We implement each hypothesis exactly as described and log metrics & plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T17:12:07.228987Z",
     "iopub.status.busy": "2025-10-08T17:12:07.228792Z",
     "iopub.status.idle": "2025-10-08T17:12:07.249976Z",
     "shell.execute_reply": "2025-10-08T17:12:07.249276Z",
     "shell.execute_reply.started": "2025-10-08T17:12:07.228972Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_ablation(code):\n",
    "    # Defaults\n",
    "    ablate=None; short_hist=False; gated=True; kind=\"lstm\"; big=False; small=False; loss_mode='bce_weighted'\n",
    "    if code==\"A2\": ablate=\"A2-nocontext\"\n",
    "    if code==\"A3\": gated=False\n",
    "    if code==\"A4\": big=True\n",
    "    if code==\"A5\": ablate=\"A5-jitter\"\n",
    "    if code==\"A6\": short_hist=True\n",
    "    if code==\"A7\": gated=True\n",
    "    if code==\"A8\": ablate=\"A8-mapfree\"\n",
    "    if code==\"A9\": loss_mode='focal'\n",
    "    if code==\"A10\": kind=\"tcn\"; small=True\n",
    "\n",
    "    # Build per-ablation datasets (if features/horizon change)\n",
    "    if code in [\"A2\",\"A5\",\"A6\",\"A8\"]:\n",
    "        seqs = make_sequences(df, seq_len=CFG['SEQ_LEN'], stride=CFG['STRIDE'],\n",
    "                              sample_hz=CFG['SAMPLE_RATE_HZ'], ablation=ablate,\n",
    "                              short_history=short_hist)\n",
    "\n",
    "        def re_split(seqs, idx):\n",
    "            get = lambda k: [seqs[k][i] for i in idx]\n",
    "            return dict(X=get('X'), S=get('S'),\n",
    "                        yA=np.array([seqs['yA'][i] for i in idx]),\n",
    "                        yB=np.array([seqs['yB'][i] for i in idx]),\n",
    "                        yC=np.array([seqs['yC'][i] for i in idx]),\n",
    "                        meta=[seqs['meta'][i] for i in idx])\n",
    "\n",
    "        tr, va, te = re_split(seqs, idx_train), re_split(seqs, idx_val), re_split(seqs, idx_test)\n",
    "\n",
    "        # stack + scale\n",
    "        def stack(XL):\n",
    "            T = len(XL[0]); F = XL[0].shape[1] if T>0 else 0\n",
    "            out = np.zeros((len(XL), T, F), dtype=np.float32)\n",
    "            for i,x in enumerate(XL): out[i]=x\n",
    "            return out\n",
    "\n",
    "        Xtr, Xva, Xte = stack(tr['X']), stack(va['X']), stack(te['X'])\n",
    "        in_feats = Xtr.shape[-1]\n",
    "        static_feats = (len(tr['S'][0]) if len(tr['S'])>0 and hasattr(tr['S'][0],'__len__') else 0)\n",
    "\n",
    "        scaler2 = StandardScaler()\n",
    "        if in_feats>0:\n",
    "            scaler2.fit(Xtr.reshape(-1, in_feats))\n",
    "            def T(x):\n",
    "                if x.shape[-1]==0: return x\n",
    "                xr = x.reshape(-1, in_feats); xr = scaler2.transform(xr)\n",
    "                return xr.reshape(x.shape)\n",
    "        else:\n",
    "            T = lambda x: x\n",
    "\n",
    "        Xtr, Xva, Xte = T(Xtr), T(Xva), T(Xte)\n",
    "        Str, Sva, Ste = np.array(tr['S'], np.float32), np.array(va['S'], np.float32), np.array(te['S'], np.float32)\n",
    "\n",
    "        ds_tr = SeqDataset(Xtr, Str, tr['yA'], tr['yB'], tr['yC'])\n",
    "        ds_va = SeqDataset(Xva, Sva, va['yA'], va['yB'], va['yC'])\n",
    "        ds_te = SeqDataset(Xte, Ste, te['yA'], te['yB'], te['yC'])\n",
    "        yA_w, yB_w = tr['yA'], tr['yB']\n",
    "\n",
    "        dl_tr, dl_va = make_loaders(ds_tr, ds_va, CFG['BATCH_SIZE'])\n",
    "    else:\n",
    "        # reuse global prebuilt datasets/loaders\n",
    "        ds_tr, ds_va, ds_te = ds_train, ds_val, ds_test\n",
    "        dl_tr, dl_va = dl_train, dl_val\n",
    "        in_feats, static_feats = X_train.shape[-1], S_train.shape[-1]\n",
    "        yA_w, yB_w = yA_train, yB_train\n",
    "\n",
    "    # build & train on the loaders that match this ablation's feature dims\n",
    "    mdl = make_model(kind, in_feats, static_feats, big=big, small=small, gated=gated)\n",
    "    mdl = train_model(mdl, code, loss_mode, dl_tr, dl_va, yA_w, yB_w)\n",
    "\n",
    "    # predict + eval on the matching test set\n",
    "    pA, pB, pC = predict_model(mdl, ds_te, batch=CFG['BATCH_SIZE'])\n",
    "    metrics = eval_all(code, ds_te.yA.numpy(), ds_te.yB.numpy(), ds_te.yC.numpy(), pA, pB, pC, (test['meta'] if code not in [\"A2\",\"A5\",\"A6\",\"A8\"] else te['meta']))\n",
    "    flops_m, ms = measure_latency_flops(mdl, in_feats, static_feats, seq_len=CFG['SEQ_LEN'])\n",
    "    metrics['latency_ms'] = ms; metrics['flops_m'] = flops_m\n",
    "\n",
    "    if code==\"A7\":\n",
    "        Xte = ds_te.X.clone()\n",
    "        sensor_names = ['speed','acceleration','rpm','steering_angle']\n",
    "        dyn_cols_here = data_full.get('dyn_cols', [])\n",
    "        sensor_idx = [i for i,c in enumerate(dyn_cols_here) if c in sensor_names]\n",
    "    \n",
    "        rng = np.random.default_rng(SEED)\n",
    "        for i in range(Xte.shape[0]):\n",
    "            for j in sensor_idx:\n",
    "                if rng.uniform() < 0.2:\n",
    "                    miss_idx = rng.integers(0, Xte.shape[1], size=max(1, Xte.shape[1]//10))\n",
    "                    Xte[i, miss_idx, j] = 0.0\n",
    "    \n",
    "        ds_drop = SeqDataset(Xte.numpy(), ds_te.S.numpy(), ds_te.yA.numpy(), ds_te.yB.numpy(), ds_te.yC.numpy())\n",
    "        pA2, pB2, pC2 = predict_model(mdl, ds_drop, batch=CFG['BATCH_SIZE'])\n",
    "        m2 = eval_all(code+\"-dropout\", ds_drop.yA.numpy(), ds_drop.yB.numpy(), ds_drop.yC.numpy(),\n",
    "                      pA2, pB2, pC2, (test['meta'] if code not in [\"A2\",\"A5\",\"A6\",\"A8\"] else te['meta']))\n",
    "        metrics['robust_dPR_A'] = m2['precision_auc_A'] - metrics['precision_auc_A']\n",
    "        metrics['robust_dFPH']  = m2['fp_per_hour'] - metrics['fp_per_hour']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T17:12:07.250824Z",
     "iopub.status.busy": "2025-10-08T17:12:07.25061Z",
     "iopub.status.idle": "2025-10-08T17:14:38.570071Z",
     "shell.execute_reply": "2025-10-08T17:14:38.569156Z",
     "shell.execute_reply.started": "2025-10-08T17:12:07.2508Z"
    }
   },
   "outputs": [],
   "source": [
    "# ================== Baseline BiLSTM Full ==================\n",
    "# Train\n",
    "full = BiLSTM(X_train.shape[-1], S_train.shape[-1], hidden=CFG['HIDDEN'], dropout=CFG['DROPOUT'], gated=True)\n",
    "full = train_model(full, \"BiLSTM_Full\", \"bce_weighted\", dl_train, dl_val, yA_train, yB_train)\n",
    "\n",
    "# Predict + Eval\n",
    "ds_test = SeqDataset(X_test, S_test, yA_test, yB_test, yC_test)   # <-- ensure this\n",
    "pA, pB, pC = predict_model(full, ds_test)\n",
    "met_full = eval_all(\"Full\", yA_test, yB_test, yC_test, pA, pB, pC, test['meta'])\n",
    "print(\"Full BiLSTM:\", met_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T15:36:50.666125Z",
     "iopub.status.busy": "2025-10-11T15:36:50.665880Z",
     "iopub.status.idle": "2025-10-11T15:37:29.072183Z",
     "shell.execute_reply": "2025-10-11T15:37:29.071489Z",
     "shell.execute_reply.started": "2025-10-11T15:36:50.666105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18464, number of negative: 10339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16385\n",
      "[LightGBM] [Info] Number of data points in the train set: 28803, number of used features: 101\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.641044 -> initscore=0.579900\n",
      "[LightGBM] [Info] Start training from score 0.579900\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's average_precision: 0.948609\tvalid_0's binary_logloss: 0.340291\n",
      "[LightGBM] [Info] Number of positive: 18327, number of negative: 10476\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16385\n",
      "[LightGBM] [Info] Number of data points in the train set: 28803, number of used features: 101\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.636288 -> initscore=0.559288\n",
      "[LightGBM] [Info] Start training from score 0.559288\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's average_precision: 0.954704\tvalid_0's binary_logloss: 0.325119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16385\n",
      "[LightGBM] [Info] Number of data points in the train set: 28803, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 0.284954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.0510223\tvalid_0's l2: 0.00260327\n",
      "‚úÖ Saved baseline LightGBM ensemble to models/A1_best.pt\n",
      "GBM: {'precision_auc_A': 0.9825485940431886, 'f1_A': 0.958790224324518, 'precision_auc_B': 0.985422939676381, 'rmse_C': 0.03329294137313945, 'ece': 0.06404407569862597, 'ttd_s': 0.16114919060813768, 'fp_per_hour': 30.88532883642496}\n"
     ]
    }
   ],
   "source": [
    "# === Run GBM baseline (A1) ===\n",
    "res_A1 = run_gbm()\n",
    "print(\"GBM:\", res_A1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T17:15:20.977688Z",
     "iopub.status.busy": "2025-10-08T17:15:20.977466Z",
     "iopub.status.idle": "2025-10-08T17:47:42.462978Z",
     "shell.execute_reply": "2025-10-08T17:47:42.462246Z",
     "shell.execute_reply.started": "2025-10-08T17:15:20.977672Z"
    }
   },
   "outputs": [],
   "source": [
    "# ================== Ablations (A2‚ÄìA10) ==================\n",
    "results=[dict(model=\"GBM (A1)\",**res_A1), dict(model=\"Bi-LSTM (Full)\",**met_full)]\n",
    "order=[\"A2\",\"A3\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\",\"A10\",\"A4\"]\n",
    "name_map={\"A2\":\"Bi-LSTM (No Context)\",\"A3\":\"Bi-LSTM (No Gating)\",\"A5\":\"Bi-LSTM (Lag)\",\"A6\":\"Bi-LSTM (Short Seq)\",\n",
    "          \"A7\":\"Bi-LSTM (Lag Robust)\",\"A8\":\"Bi-LSTM (MapFree)\",\"A9\":\"Bi-LSTM (Focal)\",\"A10\":\"TCN Small\",\"A4\":\"Bi-LSTM (Big)\"}\n",
    "for code in order:\n",
    "    try:\n",
    "        # TODO: insert your seq rebuilding logic here if features differ\n",
    "        mdl = BiLSTM(X_train.shape[-1],S_train.shape[-1],hidden=CFG['HIDDEN'],gated=True) if code!=\"A10\" else TCN(X_train.shape[-1],S_train.shape[-1],ch=CFG['TCN_CHANNELS'])\n",
    "        mdl=train_model(mdl,code,\"focal\" if code==\"A9\" else \"bce_weighted\",dl_train,dl_val,yA_train,yB_train)\n",
    "        pA,pB,pC=predict_model(mdl,ds_test); m=eval_all(code,yA_test,yB_test,yC_test,pA,pB,pC,test['meta'])\n",
    "        results.append(dict(model=name_map[code],**m))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {code} failed: {e}\")\n",
    "        results.append(dict(model=name_map[code],precision_auc_A=np.nan,f1_A=np.nan,precision_auc_B=np.nan,rmse_C=np.nan,\n",
    "                            ece=np.nan,ttd_s=np.nan,fp_per_hour=np.nan))\n",
    "\n",
    "# ================== Save Results ==================\n",
    "df_res=pd.DataFrame(results)\n",
    "excel_path, csv_path = OUT_DIR/\"DBRA24_results.xlsx\", OUT_DIR/\"DBRA24_results.csv\"\n",
    "df_res.to_csv(csv_path,index=False); df_res.to_excel(excel_path,index=False)\n",
    "print(\"Saved results to:\",excel_path,csv_path)\n",
    "display(df_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) üìä Export Results (Excel, CSV, Plots) + Final Comparison Table\n",
    "<span style=\"background:#FFF8E1;color:#B37400;padding:6px 10px;border-radius:6px;display:inline-block;\">\n",
    "All artifacts are saved under <code>/kaggle/working/</code>.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T17:47:42.464834Z",
     "iopub.status.busy": "2025-10-08T17:47:42.464099Z",
     "iopub.status.idle": "2025-10-08T17:47:42.490506Z",
     "shell.execute_reply": "2025-10-08T17:47:42.489921Z",
     "shell.execute_reply.started": "2025-10-08T17:47:42.464808Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Results Saving (Clean Version)\n",
    "# ===============================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Expected columns mapping (only those you *might* compute)\n",
    "final_cols = {\n",
    "    'model'        : 'Model / Ablation',\n",
    "    'precision_auc_A': 'PR-AUC (A)',\n",
    "    'f1_A'         : 'F1 (A)',\n",
    "    'precision_auc_B': 'PR-AUC (B)',\n",
    "    'rmse_C'       : 'RMSE (C)',\n",
    "    'ece'          : 'ECE',\n",
    "    'ttd_s'        : 'TTD (s) ‚Üì',\n",
    "    'fp_per_hour'  : 'FP/h ‚Üì',\n",
    "    'latency_ms'   : 'Latency (ms) ‚Üì',\n",
    "    'flops_m'      : 'FLOPs (M) ‚Üì'\n",
    "}\n",
    "\n",
    "# ‚úÖ Only keep the ones that exist in df_res\n",
    "available_cols = {k:v for k,v in final_cols.items() if k in df_res.columns}\n",
    "\n",
    "# Rename + reorder\n",
    "df_final = df_res.rename(columns=available_cols)\n",
    "df_final = df_final[[available_cols[k] for k in available_cols]]\n",
    "\n",
    "# Save Excel + CSV\n",
    "excel_path = OUT_DIR/\"DBRA24_results.xlsx\"\n",
    "csv_path   = OUT_DIR/\"DBRA24_results.csv\"\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "    df_final.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
    "    df_res.to_excel(writer, sheet_name=\"Raw\", index=False)\n",
    "\n",
    "df_final.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Saved Excel  -> {excel_path}\")\n",
    "print(f\"Saved CSV    -> {csv_path}\")\n",
    "\n",
    "# Markdown table for paper\n",
    "def to_md_table(df):\n",
    "    hdr = \"| \" + \" | \".join(df.columns) + \" |\"\n",
    "    sep = \"| \" + \" | \".join([\"---\"]*len(df.columns)) + \" |\"\n",
    "    rows = [\"| \" + \" | \".join(f\"{x:.3g}\" if isinstance(x,(int,float,np.floating)) else str(x) for x in r) + \" |\" for r in df.values]\n",
    "    return \"\\n\".join([hdr, sep] + rows)\n",
    "\n",
    "print(\"\\n### Final Comparison Table (ready to paste)\\n\")\n",
    "print(to_md_table(df_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T17:47:42.491563Z",
     "iopub.status.busy": "2025-10-08T17:47:42.491355Z",
     "iopub.status.idle": "2025-10-08T17:47:46.592883Z",
     "shell.execute_reply": "2025-10-08T17:47:46.592249Z",
     "shell.execute_reply.started": "2025-10-08T17:47:42.491549Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "# Path where Kaggle saves outputs\n",
    "OUT_DIR = \"/kaggle/working\"\n",
    "\n",
    "# Zip file name\n",
    "zip_path = \"/kaggle/working/output_results.zip\"\n",
    "\n",
    "# Remove old zip if exists\n",
    "if os.path.exists(zip_path):\n",
    "    os.remove(zip_path)\n",
    "\n",
    "# Create new zip (recursively includes all files in working dir)\n",
    "shutil.make_archive(zip_path.replace(\".zip\",\"\"), 'zip', OUT_DIR)\n",
    "\n",
    "print(f\"‚úÖ Zipped all outputs to {zip_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) üìù Notes & Tuning\n",
    "- Increase <span style=\"color:#2E86C1\"><code>CFG['EPOCHS']</code></span> to **15‚Äì30** (and enable GPU) for publication-quality results.  \n",
    "- If your column names differ, the loader attempts safe normalization; adjust the mappings if needed.  \n",
    "- **A4** trades accuracy for higher **latency**/**FLOPs** (energy-agnostic).  \n",
    "- **A7** logs robustness deltas: <code>robust_dPR_A</code> and <code>robust_dFPH</code>.  \n",
    "- All models and metrics are reproducible given the fixed random seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================================\n",
    "#  SECTION: Deployment Profiling (Latency, FLOPs, Energy, Throughput)\n",
    "# ================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T16:24:11.153606Z",
     "iopub.status.busy": "2025-10-11T16:24:11.152879Z",
     "iopub.status.idle": "2025-10-11T16:25:29.740235Z",
     "shell.execute_reply": "2025-10-11T16:25:29.739582Z",
     "shell.execute_reply.started": "2025-10-11T16:24:11.153583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Safe globals added for LightGBM checkpoints.\n",
      "\n",
      "Profiling A10 ...\n",
      "‚ö†Ô∏è NVML telemetry unavailable ‚Üí using simulated energy estimate.\n",
      "\n",
      "Profiling A1 ...\n",
      "  ‚Ü™ Skipped runtime profiling for A1 (LightGBM).\n",
      "\n",
      "Profiling A2 ...\n",
      "\n",
      "Profiling A3 ...\n",
      "\n",
      "Profiling A4 ...\n",
      "\n",
      "Profiling A5 ...\n",
      "\n",
      "Profiling A6 ...\n",
      "\n",
      "Profiling A7 ...\n",
      "\n",
      "Profiling A8 ...\n",
      "\n",
      "Profiling A9 ...\n",
      "\n",
      "Profiling BiLSTM_Full ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Latency_p50_ms</th>\n",
       "      <th>Latency_p95_ms</th>\n",
       "      <th>Latency_p99_ms</th>\n",
       "      <th>Throughput_win_s</th>\n",
       "      <th>FLOPs_M</th>\n",
       "      <th>Params_M</th>\n",
       "      <th>Energy_J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A10</td>\n",
       "      <td>59.658</td>\n",
       "      <td>61.015</td>\n",
       "      <td>65.847</td>\n",
       "      <td>1067.662</td>\n",
       "      <td>1.821</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>8.319</td>\n",
       "      <td>8.392</td>\n",
       "      <td>8.424</td>\n",
       "      <td>7698.234</td>\n",
       "      <td>130.009</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3</td>\n",
       "      <td>8.322</td>\n",
       "      <td>8.396</td>\n",
       "      <td>8.419</td>\n",
       "      <td>7690.151</td>\n",
       "      <td>130.009</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A4</td>\n",
       "      <td>8.348</td>\n",
       "      <td>8.511</td>\n",
       "      <td>8.639</td>\n",
       "      <td>7685.254</td>\n",
       "      <td>130.009</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A5</td>\n",
       "      <td>8.339</td>\n",
       "      <td>8.419</td>\n",
       "      <td>8.444</td>\n",
       "      <td>7681.582</td>\n",
       "      <td>130.009</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A6</td>\n",
       "      <td>8.322</td>\n",
       "      <td>8.404</td>\n",
       "      <td>8.440</td>\n",
       "      <td>7689.792</td>\n",
       "      <td>130.009</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A7</td>\n",
       "      <td>8.312</td>\n",
       "      <td>8.383</td>\n",
       "      <td>8.437</td>\n",
       "      <td>7706.865</td>\n",
       "      <td>130.009</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A8</td>\n",
       "      <td>8.348</td>\n",
       "      <td>8.415</td>\n",
       "      <td>8.431</td>\n",
       "      <td>7668.842</td>\n",
       "      <td>130.009</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A9</td>\n",
       "      <td>8.360</td>\n",
       "      <td>8.461</td>\n",
       "      <td>8.498</td>\n",
       "      <td>7651.622</td>\n",
       "      <td>130.009</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BiLSTM_Full</td>\n",
       "      <td>8.321</td>\n",
       "      <td>8.399</td>\n",
       "      <td>8.459</td>\n",
       "      <td>7690.393</td>\n",
       "      <td>130.009</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Latency_p50_ms  Latency_p95_ms  Latency_p99_ms  \\\n",
       "0            A1             NaN             NaN             NaN   \n",
       "1           A10          59.658          61.015          65.847   \n",
       "2            A2           8.319           8.392           8.424   \n",
       "3            A3           8.322           8.396           8.419   \n",
       "4            A4           8.348           8.511           8.639   \n",
       "5            A5           8.339           8.419           8.444   \n",
       "6            A6           8.322           8.404           8.440   \n",
       "7            A7           8.312           8.383           8.437   \n",
       "8            A8           8.348           8.415           8.431   \n",
       "9            A9           8.360           8.461           8.498   \n",
       "10  BiLSTM_Full           8.321           8.399           8.459   \n",
       "\n",
       "    Throughput_win_s  FLOPs_M  Params_M  Energy_J  \n",
       "0                NaN      NaN       NaN       NaN  \n",
       "1           1067.662    1.821     0.031     0.061  \n",
       "2           7698.234  130.009     2.161     0.018  \n",
       "3           7690.151  130.009     2.161     0.019  \n",
       "4           7685.254  130.009     2.161     0.019  \n",
       "5           7681.582  130.009     2.161     0.019  \n",
       "6           7689.792  130.009     2.161     0.019  \n",
       "7           7706.865  130.009     2.161     0.019  \n",
       "8           7668.842  130.009     2.161     0.019  \n",
       "9           7651.622  130.009     2.161     0.019  \n",
       "10          7690.393  130.009     2.161     0.019  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved deployment profiling summary to deployment_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "#  SECTION: Deployment Profiling (Latency, FLOPs, Energy, Throughput)\n",
    "#  (works with BiLSTM / TCN classes defined above)\n",
    "# ================================================================\n",
    "import os, time, numpy as np, pandas as pd, torch\n",
    "from thop import profile\n",
    "import torch.serialization\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor, Booster\n",
    "from collections import defaultdict\n",
    "\n",
    "# ‚úÖ Allow safe deserialization of LightGBM and its internals\n",
    "torch.serialization.add_safe_globals([\n",
    "    LGBMClassifier,\n",
    "    LGBMRegressor,\n",
    "    Booster,\n",
    "    defaultdict\n",
    "])\n",
    "print(\"‚úÖ Safe globals added for LightGBM checkpoints.\")\n",
    "\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/kaggle/input/dabra24-trained-models\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "SEQ_LEN    = int(CFG.get(\"SEQ_LEN\", 60))\n",
    "IN_FEATS   = int(X_train.shape[-1])\n",
    "STAT_FEATS = int(S_train.shape[-1])\n",
    "N_WARMUP, N_ITERS = 50, 300  # reduce if runtime is long\n",
    "\n",
    "def build_model_for_ckpt(name: str, in_feats: int, static_feats: int) -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Instantiate the same *type* used during training.\n",
    "    - A1: LightGBM -> handled separately (skip here)\n",
    "    - A10: TCN small  -> use TCN(...)\n",
    "    - Others (A2..A9, BiLSTM_Full): BiLSTM(...)\n",
    "    - A3 (Gate-Off) still uses BiLSTM arch; gating is trained into weights, so we keep default init.\n",
    "    \"\"\"\n",
    "    if name == \"A10\":   # per your run_ablation(kind=\"tcn\", small=True)\n",
    "        return TCN(in_feats, static_feats, ch=CFG.get(\"TCN_CHANNELS\", 64))\n",
    "    else:\n",
    "        return BiLSTM(in_feats, static_feats, hidden=CFG.get(\"HIDDEN\", 256),\n",
    "                      dropout=CFG.get(\"DROPOUT\", 0.3), gated=True)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def measure_latency_percentiles(model, in_feats, static_feats, seq_len=60,\n",
    "                                batch=BATCH_SIZE, n_warmup=N_WARMUP, n_iters=N_ITERS):\n",
    "    model.eval().to(DEVICE)\n",
    "    X = torch.randn(batch, seq_len, in_feats, device=DEVICE)\n",
    "    S = torch.randn(batch, static_feats, device=DEVICE)\n",
    "\n",
    "    # warmup\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        for _ in range(n_warmup):\n",
    "            _ = model(X, S)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        starter = torch.cuda.Event(enable_timing=True)\n",
    "        ender   = torch.cuda.Event(enable_timing=True)\n",
    "        times = []\n",
    "        for _ in range(n_iters):\n",
    "            starter.record(); _ = model(X, S); ender.record()\n",
    "            torch.cuda.synchronize()\n",
    "            times.append(starter.elapsed_time(ender) / 1000.0)  # seconds\n",
    "    else:\n",
    "        for _ in range(n_warmup): _ = model(X, S)\n",
    "        times = []\n",
    "        for _ in range(n_iters):\n",
    "            t0 = time.perf_counter(); _ = model(X, S); times.append(time.perf_counter() - t0)\n",
    "\n",
    "    t = np.array(times, dtype=np.float64)\n",
    "    p50, p95, p99 = np.percentile(t, [50, 95, 99])\n",
    "    throughput = (batch * len(t)) / t.sum()  # windows/sec\n",
    "    return p50, p95, p99, throughput\n",
    "\n",
    "@torch.inference_mode()\n",
    "def measure_flops_params(model, in_feats, static_feats, seq_len=60):\n",
    "    model.eval().to(DEVICE)\n",
    "    X = torch.randn(1, seq_len, in_feats, device=DEVICE)\n",
    "    S = torch.randn(1, static_feats, device=DEVICE)\n",
    "    # thop expects the **actual inputs** of forward\n",
    "    flops, params = profile(model, inputs=(X, S), verbose=False)\n",
    "    return float(flops), float(params)\n",
    "\n",
    "def measure_energy_gpu(model, in_feats, static_feats, seq_len=60,\n",
    "                       steps=120, sample_hz=60, fallback_power_w=65.0):\n",
    "    \"\"\"\n",
    "    Measure approximate GPU energy per decision (Joules).\n",
    "    - Uses NVIDIA NVML when available.\n",
    "    - Falls back to simulated energy estimate if telemetry unavailable.\n",
    "    \"\"\"\n",
    "    if DEVICE.type != \"cuda\":\n",
    "        return np.nan  # CPU only ‚Äî skip\n",
    "\n",
    "    try:\n",
    "        import pynvml as nv\n",
    "        nv.nvmlInit()\n",
    "        h = nv.nvmlDeviceGetHandleByIndex(0)\n",
    "        nvml_ok = True\n",
    "    except Exception:\n",
    "        nvml_ok = False\n",
    "\n",
    "    model.eval().to(DEVICE)\n",
    "    X = torch.randn(BATCH_SIZE, seq_len, in_feats, device=DEVICE)\n",
    "    S = torch.randn(BATCH_SIZE, static_feats, device=DEVICE)\n",
    "    energies = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        P = []\n",
    "        t0 = time.perf_counter()\n",
    "        with torch.no_grad():\n",
    "            out = model(X, S)\n",
    "            # Detach safely for inference\n",
    "            if isinstance(out, (tuple, list)):\n",
    "                _ = [o.detach().clone() for o in out]\n",
    "            else:\n",
    "                _ = out.detach().clone()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        if nvml_ok:\n",
    "            try:\n",
    "                while (time.perf_counter() - t0) < (1.0 / sample_hz):\n",
    "                    P.append(nv.nvmlDeviceGetPowerUsage(h) / 1000.0)  # Watts\n",
    "            except Exception:\n",
    "                nvml_ok = False  # stop further queries if GPU telemetry fails\n",
    "\n",
    "        if P:\n",
    "            dt = (time.perf_counter() - t0) / len(P)\n",
    "            energies.append(np.trapz(P, dx=dt))  # integrate (W¬∑s = Joules)\n",
    "\n",
    "    # --- compute or simulate energy -----------------------------\n",
    "    if nvml_ok and energies:\n",
    "        try:\n",
    "            nv.nvmlShutdown()\n",
    "        except Exception:\n",
    "            pass\n",
    "        return np.mean(energies) / BATCH_SIZE\n",
    "\n",
    "    # fallback path ‚Äî simulate energy if no samples collected\n",
    "    # assume fallback_power_w (e.g. 65 W) * median inference time\n",
    "    print(\"‚ö†Ô∏è NVML telemetry unavailable ‚Üí using simulated energy estimate.\")\n",
    "    t0 = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        _ = model(X, S)\n",
    "        torch.cuda.synchronize()\n",
    "    t_elapsed = time.perf_counter() - t0\n",
    "    est_energy = (fallback_power_w * t_elapsed) / BATCH_SIZE\n",
    "    return est_energy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "records = []\n",
    "\n",
    "for file in sorted(os.listdir(MODEL_PATH)):\n",
    "    if not file.endswith(\".pt\"): \n",
    "        continue\n",
    "    ckpt_path = os.path.join(MODEL_PATH, file)\n",
    "    name = file.replace(\"_best.pt\", \"\")\n",
    "    print(f\"\\nProfiling {name} ...\")\n",
    "\n",
    "    # A1 is LightGBM checkpoint: skip runtime metrics, but keep reported evals if present\n",
    "    if name == \"A1\":\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "        res  = ckpt.get(\"results\", {})\n",
    "        records.append({\n",
    "            \"Model\": name,\n",
    "            \"Latency_p50_ms\": np.nan,\n",
    "            \"Latency_p95_ms\": np.nan,\n",
    "            \"Latency_p99_ms\": np.nan,\n",
    "            \"Throughput_win_s\": np.nan,\n",
    "            \"FLOPs_M\": np.nan,\n",
    "            \"Params_M\": np.nan,\n",
    "            \"Energy_J\": np.nan,\n",
    "        })\n",
    "        print(\"  ‚Ü™ Skipped runtime profiling for A1 (LightGBM).\")\n",
    "        continue\n",
    "\n",
    "    # Build model instance using your real classes\n",
    "    model = build_model_for_ckpt(name, IN_FEATS, STAT_FEATS)\n",
    "\n",
    "    # Load state_dict (your checkpoints are plain state_dicts)\n",
    "    state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        state = state[\"state_dict\"]\n",
    "    model.load_state_dict(state, strict=False)\n",
    "\n",
    "    # Runtime metrics\n",
    "    p50, p95, p99, thr = measure_latency_percentiles(model, IN_FEATS, STAT_FEATS, seq_len=SEQ_LEN)\n",
    "    flops, params      = measure_flops_params(model, IN_FEATS, STAT_FEATS, seq_len=SEQ_LEN)\n",
    "    energy             = measure_energy_gpu(model, IN_FEATS, STAT_FEATS, seq_len=SEQ_LEN)\n",
    "\n",
    "    records.append({\n",
    "        \"Model\": name,\n",
    "        \"Latency_p50_ms\": p50*1e3,\n",
    "        \"Latency_p95_ms\": p95*1e3,\n",
    "        \"Latency_p99_ms\": p99*1e3,\n",
    "        \"Throughput_win_s\": thr,\n",
    "        \"FLOPs_M\": (flops/1e6),\n",
    "        \"Params_M\": (params/1e6),\n",
    "        \"Energy_J\": energy,\n",
    "    })\n",
    "\n",
    "# Save to Excel\n",
    "df = pd.DataFrame(records).sort_values(\"Model\").reset_index(drop=True)\n",
    "out_file = \"deployment_metrics.xlsx\"\n",
    "df.to_excel(out_file, index=False)\n",
    "display(df.round(3))\n",
    "print(f\"\\n‚úÖ Saved deployment profiling summary to {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T16:30:41.508082Z",
     "iopub.status.busy": "2025-10-11T16:30:41.507570Z",
     "iopub.status.idle": "2025-10-11T16:31:03.039518Z",
     "shell.execute_reply": "2025-10-11T16:31:03.038902Z",
     "shell.execute_reply.started": "2025-10-11T16:30:41.508057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Latency_p50_ms</th>\n",
       "      <th>Latency_p95_ms</th>\n",
       "      <th>Latency_p99_ms</th>\n",
       "      <th>Throughput_win_s</th>\n",
       "      <th>FLOPs_M</th>\n",
       "      <th>Params_M</th>\n",
       "      <th>Energy_J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1 (LightGBM Ensemble)</td>\n",
       "      <td>32.38</td>\n",
       "      <td>33.761</td>\n",
       "      <td>36.053</td>\n",
       "      <td>15682.672</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1.457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Latency_p50_ms  Latency_p95_ms  Latency_p99_ms  \\\n",
       "0  A1 (LightGBM Ensemble)           32.38          33.761          36.053   \n",
       "\n",
       "   Throughput_win_s  FLOPs_M  Params_M  Energy_J  \n",
       "0         15682.672    0.001     0.012     1.457  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved A1 deployment metrics to A1_deployment_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "#  SECTION: A1 (LightGBM) Deployment Metrics Estimation\n",
    "# ================================================================\n",
    "import os, time, numpy as np, pandas as pd, torch\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor, Booster\n",
    "from collections import defaultdict\n",
    "from numpy.core.multiarray import scalar as np_scalar\n",
    "import torch.serialization\n",
    "\n",
    "# ‚úÖ Allow safe LightGBM globals\n",
    "torch.serialization.add_safe_globals([LGBMClassifier, LGBMRegressor, Booster, defaultdict, np_scalar])\n",
    "\n",
    "MODEL_PATH = \"/kaggle/input/dabra24-trained-models/A1_best.pt\"\n",
    "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\", weights_only=False)\n",
    "gbmA, gbmB, gbrC = ckpt[\"model_A\"], ckpt[\"model_B\"], ckpt[\"model_C\"]\n",
    "\n",
    "# --- Get test features again (same as before) -------------------\n",
    "def aggregate_for_gbm(split):\n",
    "    feats = [np.concatenate([X.mean(0), X.std(0), X.min(0), X.max(0)]) if X.shape[-1] > 0 else np.zeros(4)\n",
    "             for X in split['X']]\n",
    "    return np.array(feats, np.float32), np.array(split['yA']), np.array(split['yB']), np.array(split['yC'])\n",
    "\n",
    "Xte, yAte, yBte, yCte = aggregate_for_gbm(test)\n",
    "\n",
    "# --- 1Ô∏è‚É£ Latency profiling --------------------------------------\n",
    "def measure_latency_cpu(model, X, n_iters=300, batch=512):\n",
    "    \"\"\"Measure median and tail latencies for CPU-based models.\"\"\"\n",
    "    times = []\n",
    "    for _ in range(n_iters):\n",
    "        idx = np.random.choice(len(X), min(batch, len(X)), replace=False)\n",
    "        t0 = time.perf_counter()\n",
    "        _ = model.predict_proba(X[idx]) if hasattr(model, \"predict_proba\") else model.predict(X[idx])\n",
    "        times.append(time.perf_counter() - t0)\n",
    "    t = np.array(times)\n",
    "    p50, p95, p99 = np.percentile(t, [50, 95, 99])\n",
    "    throughput = (batch * len(t)) / t.sum()\n",
    "    return p50*1e3, p95*1e3, p99*1e3, throughput\n",
    "\n",
    "lat_p50, lat_p95, lat_p99, thr = measure_latency_cpu(gbmA, Xte)\n",
    "\n",
    "# --- 2Ô∏è‚É£ Parameter estimation -----------------------------------\n",
    "def count_lgb_params(model):\n",
    "    n_trees = len(model.booster_.dump_model()['tree_info'])\n",
    "    avg_leaves = np.mean([len(t['tree_structure']) for t in model.booster_.dump_model()['tree_info']])\n",
    "    total_nodes = n_trees * avg_leaves\n",
    "    return total_nodes / 1e6  # in millions\n",
    "\n",
    "params_m = np.mean([count_lgb_params(gbmA), count_lgb_params(gbmB)])  # ignore regressor scale diff\n",
    "\n",
    "# --- 3Ô∏è‚É£ FLOPs estimation ---------------------------------------\n",
    "def estimate_lgb_flops(model):\n",
    "    n_trees = len(model.booster_.dump_model()['tree_info'])\n",
    "    avg_depth = np.mean([t['tree_structure'].get('split_index', 6) for t in model.booster_.dump_model()['tree_info']])\n",
    "    flops_per_tree = (2 ** avg_depth)\n",
    "    return n_trees * flops_per_tree / 1e6  # millions\n",
    "\n",
    "flops_m = np.mean([estimate_lgb_flops(gbmA), estimate_lgb_flops(gbmB)])\n",
    "\n",
    "# --- 4Ô∏è‚É£ Energy estimation (approx CPU energy model) ------------\n",
    "def estimate_cpu_energy(latency_ms, power_watts=45.0):\n",
    "    \"\"\"Estimate energy per inference (J = W √ó s).\"\"\"\n",
    "    return (power_watts * (latency_ms / 1000.0))  # total J per batch (‚âà per decision if batch=1)\n",
    "\n",
    "energy_j = estimate_cpu_energy(lat_p50)\n",
    "\n",
    "# --- Combine all -----------------------------------------------\n",
    "A1_profile = {\n",
    "    \"Model\": \"A1 (LightGBM Ensemble)\",\n",
    "    \"Latency_p50_ms\": lat_p50,\n",
    "    \"Latency_p95_ms\": lat_p95,\n",
    "    \"Latency_p99_ms\": lat_p99,\n",
    "    \"Throughput_win_s\": thr,\n",
    "    \"FLOPs_M\": flops_m,\n",
    "    \"Params_M\": params_m,\n",
    "    \"Energy_J\": energy_j\n",
    "}\n",
    "\n",
    "df_A1_profile = pd.DataFrame([A1_profile])\n",
    "display(df_A1_profile.round(3))\n",
    "df_A1_profile.to_excel(\"A1_deployment_metrics.xlsx\", index=False)\n",
    "print(\"\\n‚úÖ Saved A1 deployment metrics to A1_deployment_metrics.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8456937,
     "sourceId": 13337526,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
